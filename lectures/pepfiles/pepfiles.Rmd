---
title: "Snakemake best-practices"
subtitle: "Snakemake BYOC NBIS course"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
    xaringan::moon_reader:
        self-contained: true
        seal: false
        css: ["default", "../template.css"]
        nature:
            slideNumberFormat: ""
---
layout: true
<div class="scilife-logo"></div>
<div class="nbis-logo"></div>
---

class: center, middle

.HUGE[Configuring workflows via PEPs]

---

# Snakemake and PEPs

.SMALL[Since version 5.23.0, Snakemake supports configuration via PEP-files]

```python
pepfile: "pep/config.yaml"
pepschema: "schemas/pep.yaml"

rule all:
    input: expand("results/{sample}.stats.txt", sample = pep.sample_table["sample_name"])
```

---

# So what are PEPs?

**P**ortable **E**ncapsulated **P**rojects (or [PEPs](http://pep.databio.org/en/latest/))
is an attempt to standardize metadata and how it's used.

--
- Written in `yaml` and `csv` format
--

- Can be loaded by `R` (via `pepr`) and `python` (via `peppy`)
--

- Now supported by `Snakemake` (with Nextflow next in line?)

---

# Ok ok, but what is it _really_??

--

## Rationale

- A lot of time in bioinformatics revolves around organizing sample data

--
- Each dataset is annotated in a unique way

--
- and tools often expect sample information in a unique format

--
- This limits .green[portability] and .green[reusability] of datasets.
---

# How do PEPs make my life easier?

The idea is that PEPs help to:

1. Standardize metadata so that it works for several projects and with several tools
2. Collaborate on and share metadata with others by using a common interface
---

# How does it work with Snakemake?

--
- .small[Make sure you install `peppy` in the environment containing snakemake]

```bash
conda install -c conda-forge peppy
```
--

- .small[Create a project config file, _e.g._ `pep/config.yaml`]

```yaml
pep_version: 2.0.0
sample_table: "config/samples.csv"
```
--

- .small[Create the sample table (`config/samples.csv`)]

```bash
"sample_name","read1","read2"
"sample1","/path/to/datadir/sample1_R1.fast1.gz","/path/to/datadir/sample1_R2.fastq.gz"
"sample2","/path/to/datadir/sample2_R1.fast1.gz","/path/to/datadir/sample2_R2.fastq.gz"
```
---

# How does it work with Snakemake?

- .small[In your `Snakefile`, add the `pepfile:` directive]

```python
pepfile: "pep/config.yaml"

rule all:
    input: expand("results/{sample}.bam", sample = pep.sample_table["sample_name"])

rule align:
    input:
        R1 = lambda wildcards: pep.get_sample(wildcards.sample)["read1"],
        R2 = lambda wildcards: pep.get_sample(wildcards.sample)["read2"],
        ref = "resources/genome/genome.fasta"
    output:
        "results{sample}.bam"
    shell:
        """
        someAlignmentTool -1 {input.R1} -2 {input.R2} -x {input.ref} > {output}
        """
```
---

# Difference between pepfiles and workflow configfiles

> a PEP should describe everything needed about the data, while a workflow and its configuration should describe everything needed about the analysis that is applied to it.
---

# What else can PEPs do?

--

**Example 1: Remove hardcoded paths from the sample file**

`config/samples.csv`
```bash
"sample_name","read1","read2"
"sample1","/path/to/datadir/sample1_R1.fast1.gz","/path/to/datadir/sample1_R2.fastq.gz"
"sample2","/path/to/datadir/sample2_R1.fast1.gz","/path/to/datadir/sample2_R2.fastq.gz"
```
---

# What else can PEPs do?

**Example 1: Remove hardcoded paths from the sample file**

`config/samples.csv`
```bash
"sample_name","read1","read2"
"sample1","source1","source2"
"sample2","source1","source2"
```

`pep/config.yaml`
```yaml
pep_version: 2.0.0
sample_table: "config/samples.csv"
  derive:
    attributes: [read1, read2]
    sources:
      source1: "data/{sample_name}_R1.fastq.gz"
      source2: "data/{sample_name}_R2.fastq.gz"
```

- .green[Benefit]: If data is moved or if you want to share/publish the project
you simply update the project config

---

# What else can PEPs do?

**Example 2: Multiple input files for each sample**

Say you have samples sequenced on more than one lane and you want to include all
files in the workflow.
```bash
data/
├── L001
	 ├── sample1_L001_R1.fastq.gz
	 ├── sample1_L001_R2.fastq.gz
	 ├── sample2_L001_R1.fastq.gz
	 └── sample2_L001_R2.fastq.gz
├── L002
	 ├── sample1_L002_R1.fastq.gz
	 ├── sample1_L002_R2.fastq.gz
	 ├── sample2_L002_R1.fastq.gz
	 └── sample2_L002_R2.fastq.gz
```

---

# What else can PEPs do?

**Example 2: Multiple input files for each sample**

- Option1: Use wildcards in project config

`pep/config.yaml`
```yaml
pep_version: 2.0.0
sample_table: "../config/samples.csv"
sample_modifiers:
  derive:
    attributes: [read1, read2]
    sources:
      source1: "data/L*/{sample_name}_L*_R1.fastq.gz"
      source2: "data/L*/{sample_name}_L*_R2.fastq.gz"
```
---

# What else can PEPs do?

**Example 2: Multiple input files for each sample**

- Option2: Use a subsample table

`pep/config.yaml`
```yaml
pep_version: 2.0.0
sample_table: "config/samples.csv"
subsample_table: "config/subsample_table.csv"
```
--

`config/sample_table.csv`
```yaml
"sample_name"
"sample1"
"sample2"
```

`config/subsample_table.csv`
```yaml
"sample_name","read1","read2"
"sample1","data/L001/sample1_L001_R1.fastq.gz","data/L001/sample1_L001_R2.fastq.gz"
"sample1","data/L002/sample1_L002_R1.fastq.gz","data/L002/sample1_L002_R2.fastq.gz"
"sample2","data/L001/sample2_L001_R1.fastq.gz","data/L001/sample2_L001_R2.fastq.gz"
"sample2","data/L002/sample2_L002_R1.fastq.gz","data/L002/sample2_L002_R2.fastq.gz"
```

--
.green[Benefit]: Your main sample table can still describe one sample per line.

---

# What else can PEPs do?

**Example 3: Modify your project on the fly**

Say you have a Snakemake project set up for a particular dataset and genomic reference.
Further down the line you get a new dataset that should use another genome
reference.

--

With PEPs you can easily .green[amend] your current project to point to the new
dataset _and_ use the other genome reference.

---

# What else can PEPs do?

**Example 3: Modify your project on the fly**

`pep/config.yaml`
```yaml
pep_version: 2.0.0
sample_table: "../config/samples.csv"
genome: ref1
sample_modifiers:
  derive:
    attributes: [read1, read2]
    sources:
      source1: "data/L*/{sample_name}_L*_R1.fastq.gz"
      source2: "data/L*/{sample_name}_L*_R2.fastq.gz"
```

---

# What else can PEPs do?

**Example 3: Modify your project on the fly**

`pep/config.yaml`
```yaml
pep_version: 2.0.0
sample_table: "../config/samples.csv"
genome: ref1
sample_modifiers:
  derive:
    attributes: [read1, read2]
    sources:
      source1: "data/L*/{sample_name}_L*_R1.fastq.gz"
      source2: "data/L*/{sample_name}_L*_R2.fastq.gz"
project_modifiers:
  amend:
    batch2:
      sample_table: "../config/samples_batch2.csv"
      genome: ref2
```

--

Then activate that amendment if you want to use it in your workflow:

```python
pepfile: "pep/config.yaml"
pep.activate_amendments("batch2")
```

--

.green[Benefit]: Quickly change setup with little duplication

---

# More resources

- [Snakemake docs](https://snakemake.readthedocs.io/en/stable/snakefiles/configuration.html#configuring-scientific-experiments-via-peps)
- [PEP docs](http://pep.databio.org/en/latest/)
- [peppy package](http://peppy.databio.org/en/latest/)
- [pepr package](http://code.databio.org/pepr/)

---

class: center, middle
# Questions?
