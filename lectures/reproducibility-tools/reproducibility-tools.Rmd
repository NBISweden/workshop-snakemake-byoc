---
title: "Combining Tools for Reproducible Research with Snakemake"
subtitle: "Snakemake BYOC NBIS course"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
    xaringan::moon_reader:
        self-contained: true
        seal: false
        css: ["default", "../template.css"]
        nature:
            slideNumberFormat: ""
---

layout: true
<div class="scilife-logo"></div>
<div class="nbis-logo"></div>

---

class: center, middle

.HUGE[Combining Tools for Reproducible Research with Snakemake]

```{r Setup, echo = FALSE, message = FALSE}
# Knitr setup
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

# Load packages
library("dplyr")
library("kableExtra")
```

---

# Reproducibility is rarer than you think

The results of only 26% out of 204 randomly selected papers in the journal
*Science* could be reproduced.<sup>1</sup>

.tiny[<sup>1</sup> Stodden et. al (2018). "An empirical analysis of journal policy effectiveness for computational reproducibility". PNAS. 115 (11): 2584-2589]

--

> Many journals are revising author guidelines to include data and code
> availability.

--

> (...) an improvement over no policy, but currently insufficient for
> reproducibility.


---

# Combining Tools for Reproducible Research with Snakemake

.center[<img src="reproducibility-overview.png" width=40%/>]

--

* Track your Snakemake code with .green[Git] and push it to a remote .green[repository] on GitHub or BitBucket to ensure that the different code versions are tracked and available

--

* Combine Snakemake with .green[Conda] and/or .green[containers] to make the compute environment and the code reproducible

--

* Integrate foreign workflow management systems such as .green[Nextflow] pipelines into your Snakemake workflow

---

# Git

* A widely used system for distributed version control to .green[version, backup and share] your code and documents

--

* Keeps a complete .green[history] of the changes you make to your files that can be re-visited & compared

--

* Git tracks .green[who contributed what] to your code

--

* Git is mainly used for .green[text files], not large or binary files, so ideal for Snakemake workflows

--

* You can publish your code along with your research paper by sharing it in a remote repository (e.g. on .green[GitHub] or .green[BitBucket])

---

# Git

.center[<img src="git_overview_remote.png" style="width:50%"/>]

--

1. Do some .green[coding] (*i.e.* add or change contents of files)

--

2. .green[Stage] the changes (*i.e.* specify which changes should be stored)

--

3. .green[Commit] the changes (storing them in the repository's history)

--

4. .green[Push] and .green[pull] regularly to/from your remote repository (on GitHub or Bitbucket) to collaborate, backup and share your code

---

# Conda

* Is a .green[package, dependency, and environment] manager

--

    > packages: any type of program (_e.g._ bowtie2, snakemake etc.)

    > dependency: other software required by a package

    > environment: a distinct collection of packages

--

* Keeps track of the dependencies between packages in each environment

---

# Conda

## Running a Snakemake rule with a Conda environment

--

* Make sure you have Conda .green[installed] (Miniconda or Anaconda)

--

* Find your Conda .green[package] on http://anaconda.org

--

* Create a Conda .green[environment file] (e.g. `bwa.yaml`)

```{python conda env one, eval = FALSE}
channels:
  - conda-forge
  - bioconda
  - defaults
dependencies:
  - bwa=0.7.17
```

.small[_(from best practice snakemake workflow: https://github.com/NBISweden/snakemake_best_practice)_]


--

* Store your `yaml` files in a directory for environments

--

* For reproducibility, it is important to keep include package .green[versions] in your environment file

--

* .green[Git] is ideal to track changes in your Conda environment files

---

# Conda

## Running a Snakemake rule with a Conda environment

* Add the .green[path] to the Conda environment `yaml` file to your rule using the `conda` directive

--

```{python conda rule, eval = FALSE}
rule map_bwa_index:
    output: expand("{{ref}}{ext}", ext=[".amb", ".ann", ".bwt", ".pac", ".sa"])
    input: config["ref"]
    log: "logs/bwa/index/{ref}.log"
    conda: "../envs/bwa.yaml"
    shell:
        "bwa index {input}"
```

.small[_(modified from best practice snakemake workflow: https://github.com/NBISweden/snakemake_best_practice)_]

--

* Start your workflow on the command line with `--use-conda`

```{bash snakemake use conda, eval=FALSE}
$ snakemake --use-conda
```

--

* This doesn't work if you use `run` instead of `shell` (or other directives)

---

# Conda

## Using a Conda environment for the entire workflow

--

* Write a Conda .green[environment file] that includes all tools used by the workflow, or those used by rules with `run` directives (save it as e.g. `environment.yaml`)

```{python conda env big, eval=FALSE}
name: best-practice-smk
channels:
  - conda-forge
  - bioconda
  - default
dependencies:
  - snakemake=6.8.0
  - python=3.8
  - pandas=1.3.3
  - jupyter=1.0
  - jupyter_contrib_nbextensions=0.5.1
  - jupyterlab_code_formatter=1.4
  - bwa=0.7.17
  - multiqc=1.11
  - r-ggplot2=3.3.5
  - samtools=1.13
```

.small[_(from best practice snakemake workflow: https://github.com/NBISweden/snakemake_best_practice)_]

---

# Conda

## Using a Conda environment for the entire workflow

* .green[Create] the environment

--

```{bash conda create, eval=FALSE}
$ conda env create -f environment.yml
```

--

* Use a terminal multiplexer to run the workflow in a shell instance in the background, _e.g._ .green[tmux] or .green[screen]

--

* .green[Activate] your Conda environment in the tmux or screen session

```{bash conda activate, eval=FALSE}
$ conda activate best-practice-smk
```

--

* Start your Snakemake workflow

```{bash snakemake conda env, eval=FALSE}
(best-practice-smk) [...] $ snakemake
```

---

# Docker & Singularity

--

## What can I use Docker for?

* Run applications securely .green[isolated] in a container, packaged with .green[all dependencies and libraries]

--

* As advanced .green[environment manager]

--

* To package your .green[code] with the environment it needs

--

* To package a whole .green[workflow] (*e.g.* to accompany a manuscript)

--

* And much more

--

## Singularity 

* Is an open source container platform suitable for .green[HPC clusters]

---

# Docker & Singularity

## Docker nomenclature

--

* A Docker .green[file] is a recipe used to build a Docker .green[image]

--

* A Docker .green[image] is a standalone executable package of software

--

* A Docker .green[container] is a standard unit of software run on the Docker Engine

--

* .green[DockerHub] is an online service for sharing docker images

--

* Docker images can be converted into Singularity images

---

# Docker & Singularity

## Running Snakemake rules with Singularity

--

* Snakemake can run a rule .green[isolated] in a container, using Singularity

--

* Each Conda package is also available as Docker and Singularity images (_e.g._ check http://biocontainers.pro for Conda packages from the bioconda channel)

--

* Many other Docker images are also available on DockerHub (https://hub.docker.com/)
    * But be aware that Docker images in free accounts are automatically deleted after a certain time of inactivity

---

# Docker & Singularity

## Running Snakemake rules with Singularity

--

* Make sure your system has Singularity .green[installed]

--

* Find your Docker or Singularity .green[image], _e.g._ on http://biocontainers.pro

--

* Add the .green[link] to the container image (or the path to a Singularity `*.sif` file) to your rule using the `container` directive

```{python singularity rule, eval = FALSE}
rule NAME:
    input:
        "table.txt"
    output:
        "plots/myplot.pdf"
    container:
        "docker://joseespinosa/docker-r-ggplot2"
    script:
        "scripts/plot-stuff.R"
```

.small[_(example from Snakemake documentation)_]

--

* Start your workflow on the command line with `--use-singularity`

```{bash snakemake use singularity, eval=FALSE}
$ snakemake --use-singularity
```

---

# Docker & Singularity

## Packaging your Snakemake workflow in a Docker container

--

* Write a .green[Docker file] (`my_workflow`), _e.g._

--

    * Start with the official Miniconda `base` image
    * Install the core packages of the workflow (_e.g._ Snakemake and dependencies such as pandas)
    * Include all rule-specific environments as separate Conda files (running your rules with Conda)
    * Include your workflow with `COPY <local-src> <container-destination>` into the Docker file
    * Include the required input data, _e.g._
        * Mount the path with the data inside the container
        * Mount a sample list, specifying their data paths

---

# Docker & Singularity

## Packaging your Snakemake workflow in a Docker container

* Create a Docker .green[image] from your Docker file (_e.g._ called `my_workflow`)

```{bash docker image, eval=FALSE}
$ docker build -t my_workflow .
```

--

* .green[Run] your container

```{bash docker run, eval=FALSE}
$ docker run --name my_first_workflow_instance -it my_workflow
```

--

* .green[Share] your Docker file on GitHub or BitBucket, or your Docker image on DockerHub

---

# Docker & Singularity

## Containerization of Conda based workflows

* Snakemake can .green[automatically] generate a Docker container image that contains all
  Conda environments specified with the `conda` directive in the rules of the workflow

--

* Generate a .green[Docker file] with `--containerize`

```{python containerize, eval = FALSE}
snakemake --containerize > Dockerfile
```

--

* The Docker .green[image] from this Docker file can then be used via the directive `containerized` (globally or per rule): 

```{python containerization, eval = FALSE}
containerized: "docker://username/myworkflow:1.0.0"

rule NAME:
    input:
        "table.txt"
    output:
        "plots/myplot.pdf"
    conda:
        "envs/ggplot.yaml"
    script:
        "scripts/plot-stuff.R"
```

.small[_(example from Snakemake documentation)_]

---

# Integrating foreign workflow management systems

* From version 6.2 on, Snakemake can run workflows written in other workflow 
  management systems such as .green[Nextflow] 

--

* The workflow is run in Snakemake until a .green[rule] to run the foreign workflow
  is reached

--

* In this rule, Snakemake .green[hands over] to the other workflow management system 
  indicated by the directive `handover`

```{python nextflow, eval = FALSE}
rule chipseq_pipeline:
    input:
        input="design.csv",
        fasta="data/genome.fasta",
        gtf="data/genome.gtf",
    output:
        "multiqc/broadPeaks/multiqc_report.html",
    params:
        pipeline="nf-core/chipseq",
        revision="1.2.1",
        profile=["conda"],
    handover: True
    wrapper:
        "0.74.0/utils/nextflow"
```

.small[_(example from Snakemake documentation)_]


---

# Integrating foreign workflow management systems

* The handover rule is run .green[locally]

--

* .green[Job submissions] to the cluster or cloud system are handled by the other workflow management system

--

* Afterwards, .green[Snakemake] continues running rules that use the output files of the foreign workflow

---

# Summary

There are many ways to use other .green[tools for reproducible research] together with Snakemake:

--

* Use .green[Git] to version control, backup and share your code

--

* Run rules or your entire workflow in .green[Conda] environments

--

* Run your rules in isolated Docker or Singularity .green[containers] using Singularity

--

* Package your entire workflow in a .green[Docker container]

--

* Run pipelines written in .green[other workflow management systems] in your Snakemake workflow

---

class: center, middle

.HUGE[Questions?]

---