---
title: "Reproducible Research and Snakemake"
subtitle: "Snakemake BYOC NBIS course"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
    xaringan::moon_reader:
        self-contained: true
        seal: false
        css: ["default", "../template.css"]
        nature:
            slideNumberFormat: ""
---

layout: true
<div class="scilife-logo"></div>
<div class="nbis-logo"></div>

---

class: center, middle

.HUGE[Reproducible Research and Snakemake]

```{r Setup, echo = FALSE, message = FALSE}
# Knitr setup
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

# Load packages
library("dplyr")
library("kableExtra")
```

---

# Reproducibility

- Reproducible research is about being able to replicate the results of a study
- It is an important aspect of the scientific method
- Computational reproducibility is one part of it
- Given the same data and the same code, we expect identical outcomes

---

# Computational reproducibility

Why the effort?

> Because many researchers typically forget details
> of their own work, they are not unlike strangers
> when returning to projects after time away.
> Thus, efforts to communicate your work to
> strangers can actually help you communicate
> with yourself over time.

M. Schwab et al. *Making scientific computations reproducible*. https://dx.doi.org/10.1109/5992.881708

→ It’s for **you**


---

# Don’t be *that* person

The journal *Science* implemented a replication policy in 2011.
A study in 2018 requested raw data and code in accordance with the policy. Some answers:

> When you approach a PI for the source codes and raw data, you better explain who you are, whom you work for, why you need the data and what you are going to do with it.

.
--

> I have to say that this is a very unusual request without any explanation! Please ask your supervisor to send me an email with a detailed, and I mean detailed, explanation.

(26% out of 204 randomly selected papers in the journal could be reproduced.)

.tiny[Stodden et. al (2018). *An empirical analysis of journal policy effectiveness for computational reproducibility* https://doi.org/10.1073/pnas.1708290115]

---

# Combining Tools for Reproducible Research with Snakemake

.center[<img src="reproducibility-overview.png" width=40%/>]

--

* Track your code with .green[Git] and share it in a remote .green[repository] on GitHub or BitBucket (not covered in this lecture)

--

* Combine Snakemake with .green[Conda] and/or .green[containers] to make the compute environment reproducible

--

* Integrate foreign workflow management systems such as .green[Nextflow] pipelines into your Snakemake workflow

---

# Conda

* Is a .green[package, dependency, and environment] manager

--

    > packages: any type of program (_e.g._ bowtie2, snakemake etc.)

    > dependency: other software required by a package

    > environment: a distinct collection of packages

--

* Keeps track of the dependencies between packages in each environment

---

# Conda

## 1. Running a Snakemake rule with a Conda environment

--

* Make sure you have Conda .green[installed] (Miniconda or Anaconda)

--

* Find your Conda .green[package] on http://anaconda.org

--

* Create a Conda .green[environment file] (e.g. `bwa.yaml`)

```{python conda env one, eval = FALSE}
channels:
  - conda-forge
  - bioconda
  - defaults
dependencies:
  - bwa=0.7.17
```

.tiny[source: [best practice example](https://github.com/NBISweden/snakemake_best_practice)]


--

* Store your `yaml` files in a directory for environments

--

* For reproducibility, it is important to keep include package .green[versions] in your environment file

---

# Conda

## 1. Running a Snakemake rule with a Conda environment

* Add the .green[path] to the Conda environment `yaml` file to your rule using `conda`

--

```{python conda rule, eval = FALSE}
rule map_bwa_index:
    output: expand("{{ref}}{ext}", ext=[".amb", ".ann", ".bwt", ".pac", ".sa"])
    input: config["ref"]
    log: "logs/bwa/index/{ref}.log"
    conda: "../envs/bwa.yaml"
    shell:
        "bwa index {input}"
```

.tiny[modified from: [best practice example](https://github.com/NBISweden/snakemake_best_practice)]

--

* Start your workflow on the command line with `--use-conda`

```{bash snakemake use conda, eval=FALSE}
$ snakemake --use-conda
```

--

* This doesn't work if you use `run` (instead of `shell` or `script`)

---

# Conda

## 2. Using one Conda environment for the entire workflow

--

* Write a Conda .green[environment file] that includes all tools used by the workflow (save it as e.g. `environment.yaml`)

```{python conda env big, eval=FALSE}
name: best-practice-smk
channels:
  - conda-forge
  - bioconda
  - default
dependencies:
  - snakemake=6.8.0
  - python=3.8
  - pandas=1.3.3
  - jupyter=1.0
  - jupyter_contrib_nbextensions=0.5.1
  - jupyterlab_code_formatter=1.4
  - bwa=0.7.17
  - multiqc=1.11
  - r-ggplot2=3.3.5
  - samtools=1.13
```

.tiny[source: [best practice example](https://github.com/NBISweden/snakemake_best_practice)]

---

# Conda

## 2. Using one Conda environment for the entire workflow

* .green[Create] the environment

--

```{bash conda create, eval=FALSE}
$ conda env create -f environment.yml
```

--

* .green[Activate] your Conda environment

```{bash conda activate, eval=FALSE}
$ conda activate best-practice-smk
```

--

* Start your Snakemake workflow

```{bash snakemake conda env, eval=FALSE}
(best-practice-smk) [...] $ snakemake
```

---

# Containers

## What can I use containers for?

--

* Run applications securely .green[isolated] in a container, packaged with .green[all dependencies and libraries]

--

* As advanced .green[environment manager]

--

* To package your .green[code] with the environment it needs

--

* To package a whole .green[workflow] (*e.g.* to accompany a manuscript)

--

* And much more

--

## Docker vs. Singularity

--

* Docker was developed for .green[any operating system] except high-performance computing (HPC) clusters

--

* Singularity is an open source container platform suitable for .green[HPC clusters]

---

# Containers

## Docker nomenclature

--

* A Docker .green[file] is a recipe used to build a Docker .green[image]

--

* A Docker .green[image] is a standalone executable package of software

--

* A Docker .green[container] is a standard unit of software run on the Docker Engine

--

* .green[DockerHub] is an online service for sharing Docker images

--

* Docker images can be converted into Singularity images

---

# Containers

## 1. Running Snakemake rules with Singularity

--

* Snakemake can run a rule .green[isolated] in a container, using Singularity

--

* All Conda packages are available as Docker and Singularity images, _e.g._ on http://biocontainers.pro (bioconda channel)

--

* Many other Docker images are available on [DockerHub](https://hub.docker.com/)

--

* Or build your own Docker or Singularity images

---

# Containers

## 1. Running Snakemake rules with Singularity

--

* Make sure your system has Singularity .green[installed]

--

* Find the Docker or Singularity .green[image] in which you want to run the rule

--

* Add the .green[link] to the container image (or the path to a Singularity `*.sif` file) to your rule using the `container` directive

```{python singularity rule, eval = FALSE}
rule NAME:
    input:
        "table.txt"
    output:
        "plots/myplot.pdf"
    container:
        "docker://joseespinosa/docker-r-ggplot2"
    script:
        "scripts/plot-stuff.R"
```

.tiny[source: [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#running-jobs-in-containers)]

--

* Start your workflow on the command line with `--use-singularity`

```{bash snakemake use singularity, eval=FALSE}
$ snakemake --use-singularity
```

---

# Containers

## 2. Packaging your Snakemake workflow in a Docker container

--

* Make sure your system has Docker .green[installed]

--

* Write a .green[Docker file], _e.g._ [see this example](https://github.com/NBISweden/workshop-reproducible-research/blob/main/tutorials/docker/Dockerfile)

--

    * Start with the official `Ubuntu` image 
    * Install Miniconda and other required tools (_e.g._ Snakemake)
    * Add the project files (e.g. `Snakefile`, `config.yaml`, `environment.yaml`)
    * Install the Conda environment containing all packages run by the workflow

---

# Containers

## 2. Packaging your Snakemake workflow in a Docker container

* Create a Docker .green[image] from your Docker file (_e.g._ called `my_workflow`)

```{bash docker image, eval=FALSE}
$ docker build -t my_workflow .
```

--

* .green[Run] your container, _e.g._

```{bash docker run, eval=FALSE}
$ docker run my_workflow
```

--

* .green[Share] your Docker file on GitHub or BitBucket, or your Docker image on DockerHub

---

# Combinations of Conda and Containers

## Combine Conda-based package management with running jobs in containers

--

* A container can be specified globally (for the entire workflow) for a workflow 
  with rule-specific Conda environments

* Snakemake then runs each job in this container with its corresponding Conda 
  environment when run with `--use-conda --use-singularity`

.tiny[More info: [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#ad-hoc-combination-of-conda-package-management-with-containers) & [best practice example](https://github.com/NBISweden/snakemake_best_practice)]

---

# Combinations of Conda and Containers

## Containerization of Conda-based workflows

--

* Snakemake can automatically generate a Docker file that contains all
  Conda environments used by the rules of the workflow using the flag `--containerize` 

.tiny[More info: [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#containerization-of-conda-based-workflows)]

---

# Integrating foreign workflow management systems

* From version 6.2 on, Snakemake can run workflows written in other workflow 
  management systems such as .green[Nextflow] 

--

.pull-left[

* The workflow runs in .green[Snakemake] until a rule to run the foreign workflow is reached

* In this rule, Snakemake .green[hands over] to the other workflow manager

* Afterwards, .green[Snakemake] continues to run rules processing the output files of the foreign workflow

]

--

.pull-right[

```{python nextflow, eval = FALSE}
rule chipseq_pipeline:
    input:
        input="design.csv",
        fasta="data/genome.fasta",
        gtf="data/genome.gtf",
    output:
        "multiqc/broadPeaks/multiqc_report.html",
    params:
        pipeline="nf-core/chipseq",
        revision="1.2.1",
        profile=["conda"],
    handover: True
    wrapper:
        "0.74.0/utils/nextflow"
```

.tiny[More info & source: [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/foreign_wms.html)]

]

---

# Summary

There are many ways to use other .green[tools for reproducible research] together with Snakemake:

--

* Use .green[Git] to version control, backup and share your code

--

* Run rules or your entire workflow in .green[Conda] environments

--

* Run your rules in isolated Singularity .green[containers]

--

* Package your entire workflow in a .green[Docker container]

--

* Run pipelines written in .green[other workflow management systems] in your Snakemake workflow

---

class: center, middle

.HUGE[Questions?]

---
