---
title: "Reproducible Research and Snakemake"
subtitle: "Snakemake BYOC NBIS course"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
    xaringan::moon_reader:
        self-contained: true
        seal: false
        css: ["default", "../template.css"]
        nature:
            slideNumberFormat: ""
---

layout: true
<div class="scilife-logo"></div>
<div class="nbis-logo"></div>

---

class: center, middle

.HUGE[Reproducible Research and Snakemake]

```{r Setup, echo = FALSE, message = FALSE}
# Knitr setup
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

# Load packages
library("dplyr")
library("kableExtra")
```

---

# Reproducibility

- Reproducible research is about being able to replicate the results of a study
- It is an important aspect of the scientific method
- Computational reproducibility is one part of it
- Ideally, given the same data and the same code, there are identical outcomes

--

*Code* encompasses
- The workflow itself (→ `Snakefile`)
- The helper scripts you are calling (→ `scripts/`)
- The 3rd-party tools you are running (→ this lecture)

---

# Computational reproducibility

Why the effort?

.tiny[M. Schwab et al. *Making scientific computations reproducible*. https://dx.doi.org/10.1109/5992.881708]

> Because many researchers typically forget details
> of their own work, they are not unlike strangers
> when returning to projects after time away.
> Thus, efforts to communicate your work to
> strangers can actually help you communicate
> with yourself over time.

--

→ **You** are also in the target audience


---

# Don’t be *that* person

The journal *Science* implemented a replication policy in 2011.
A study in 2018 requested raw data and code in accordance with the policy.
Some answers:

> When you approach a PI for the source codes and raw data, you better explain who you are,
> whom you work for, why you need the data and what you are going to do with it.

.
--

> I have to say that this is a very unusual request without any explanation!
> Please ask your supervisor to send me an email with a detailed, and I mean detailed, explanation.

(26% out of 204 randomly selected papers in the journal could be reproduced.)

.tiny[Stodden et. al (2018). *An empirical analysis of journal policy effectiveness for computational reproducibility* https://doi.org/10.1073/pnas.1708290115]

---

# Combine tools to make research reproducible

.center[<img src="reproducibility-overview.png" width=40%/>]

--

* Track code changes over time with .green[Git] and share it on [GitHub](https://github.com) (not this talk)

--

* Make your workflow reproducible with a workflow manager (.green[Snakemake], .green[Nextflow], .green[WDL])

--

* Make the execution environment reproducible with .green[Conda] environments and/or .green[containers]


---

# Conda: a .green[package], .green[dependency], and .green[environment] manager

* Conda installs packages
* Packages come from a central repository at https://anaconda.org/
* Users can contribute their own packages via *channels*
* Highly recommended: The [Bioconda](https://bioconda.github.io/) channel

---

# Using Conda

Prerequisites

* Install Conda, for example with [Miniconda](https://docs.conda.io/en/latest/miniconda.html)

* Set up the [Bioconda](https://bioconda.github.io/) channel

--

* Install Samtools and BWA into a new Conda environment named `mapping`:
```
$ conda create -n mapping samtools bwa
```

--

* Conda also installs also the .green[dependencies] – other software required by Samtools and/or BWA.

--

To use the tools in the environment, .green[activate] it:
```
$ conda activate mapping
$ samtools --version
samtools 1.15.1
```

--
* Install a tool into an existing environment:
```
conda install -n mapping bowtie2
```
(Leaving out `-n mapping` installs into the currently active environment.)

---

# Conda environments

* You can have as many environments as you wish

* Environments are independent from each other

* If something is broken, simply delete the environment and start over

* To test a new tool, install it into a Conda environment. Delete the environment to uninstall.

--

* Find tools to install by searching [anaconda.org](https://anaconda.org) or with `conda search`


---

# Conda environment files

* Conda environments can be created from .green[environment files] in YAML format.

* Example `bwa.yaml`:

```{yaml conda env one, eval = FALSE}
channels:
  - conda-forge
  - bioconda
  - defaults
dependencies:
  - bwa=0.7.17
```

--
* Create the environment:
```{bash, eval = FALSE}
$ conda env create -n bwa -f bwa.yaml
```

---

# Snakemake + Conda

## Option one: A single environment for the entire workflow

* Write an environment file (`environment.yaml`) that includes .green[all tools used by the workflow]:
```{python conda env big, eval=FALSE}
name: best-practice-smk
channels:
  - conda-forge
  - bioconda
  - default
dependencies:
  - snakemake=6.8.0   # ← Snakemake is part of the environment
...
  - multiqc=1.11   # ← Version numbers for reproducibility
  - samtools=1.13
```

--
* Create the environment, activate it and run the workflow within it:
```{bash snakemake conda env, eval=FALSE}
$ conda env create -f environment.yml
$ conda activate best-practice-smk
$ snakemake
```

--
* Possibly helpful: `conda export -n envname > environment.yaml`

.tiny[source: [best practice example](https://github.com/NBISweden/snakemake_best_practice)]

---
# Snakemake + Conda

## Option two: Rule-specific environments

You can let Snakemake create and activate Conda environments for you.

--
1. Create the environment file, such as `envs/bwa.yaml` (`envs/` is best practice)

--
1. Add the `conda:` directive to the rule:
```{python conda rule, eval = FALSE}
rule create_bwa_index:
    output: ...
    input: ...
    conda: "envs/bwa.yaml"  # ← Path to environment YAML file
    shell:
        "bwa index {input}"
```
--
1. Run `snakemake --use-conda`

--

* Snakemake creates the environment for you and re-uses it next time
* If the YAML file changes, the environment is re-created
* `conda:` does not work if you use `run:` (instead of `shell:` or `script:`)


.tiny[modified from: [best practice example](https://github.com/NBISweden/snakemake_best_practice)]


---

# Using a "module" system

* Conda environments can be large and slow to create

* Some cluster operators frown upon using it

--

* UPPMAX and other clusters have a .green[module] command for getting access to software:
```
$ module load bioinfo-tools bwa
```

--

* Snakemake supports this with the `envmodules:` directive:
```{bash, eval = FALSE}
rule create_bwa_index:
    output: ...
    input: ...
    envmodules:
      "bioinfo-tools",
      "bwa",
    conda: "envs/bwa.yaml"  # ← Fallback
    shell:
        "bwa index {input}"
```

--

* Run with `snakemake --use-envmodules`

--

* For reproducibility, [the Snakemake documentation recommends](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#using-environment-modules) to also include a `conda:` section

---

# Containers

* Containers represent another way of packaging applications

--

* Each container contains the application itself and .green[all dependencies and libraries] (that is, a functional Linux installation)

--

* It is fully .green[isolated] from the other software on the machine:
  By default, the tools in the container can only access what is in the container.

--

* The most common software for managing containers is .green[Docker]

---

# Containers

## Docker nomenclature

--
* A Docker .green[image] is a standalone executable package of software (on disk)

--
* A .green[Dockerfile] is a recipe used to build a Docker .green[image]

--
* A Docker .green[container] is a standard unit of software run on the Docker Engine
  (running an image gives a container)

--
* .green[DockerHub] is an online service for sharing Docker images

--

## Docker vs Singularity

* On high-performance clusters (HPC), Docker is often not installed due to security concerns.
  .green[Singularity] is often available as an alternative.

--
* Docker images can be converted into Singularity images

--
* → Singularity can be used to run Docker containers

---

# Running Snakemake jobs in containers

Snakemake can run a jobs in a container using Singularity

* Ensure your system has Singularity .green[installed]

--

* Find a Docker or Singularity image with the tool to run (https://biocontainers.pro/ or [DockerHub](https://hub.docker.com/))

--

* Add the `container:` directive to your rule:

```{python singularity rule, eval = FALSE}
rule minimap2_version:
    container: "docker://quay.io/biocontainers/minimap2:2.24--h5bf99c6_0"   # ← "docker://" is needed
    shell:
        "minimap2 --version"
```

--

* Start your workflow on the command line with `--use-singularity`

```{bash snakemake use singularity, eval=FALSE}
$ snakemake --use-singularity -j 1
...
Activating singularity image .../.snakemake/singularity/342e6ddbac7e5929a11e6ae9350454c0.simg
INFO:    Converting SIF file to temporary sandbox...
2.24-r1122
INFO:    Cleaning up image...
...
```

---

# Containers – advanced topics

* A [Docker image to use for *all* rules can be specified](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#running-jobs-in-containers)

--
* You can package your entire workflow into a Docker image by writing a .green[Dockerfile].
  [See this example](https://github.com/NBISweden/workshop-reproducible-research/blob/0ee1eca78ccefbd06fbeb2c0aba37030230df90d/tutorials/containers/Dockerfile)
  - Snakemake runs *inside* the container.
  - To run the workflow, only Docker or Singularity is needed

--
* [Conda and containers can be combined]([Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#ad-hoc-combination-of-conda-package-management-with-containers): Specify a global container, run with `--use-conda --use-singularity`, and Snakemake creates the Conda environment within the container.

--
* [Snakemake can automatically generate a Dockerfile](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#containerization-of-conda-based-workflows)
  that contains all Conda environments used by the rules of the workflow using the flag
  `--containerize`.

---

# Summary

There are many ways to use other .green[tools for reproducible research] together with Snakemake:

--

* Use .green[Git] for version control, backup and share your code

--

* Run rules or your entire workflow in .green[Conda] environments

--

* Run your rules in isolated Docker/Singularity .green[containers]

--

* Package your entire workflow in a .green[Docker container]


<!--

* Further reading: [conda-lock](https://github.com/conda-incubator/conda-lock)


  * This starts from an Ubuntu image, installs Miniconda, Snakemake, adds relevant files such as `the workflow files
    * Install Miniconda and other required tools (_e.g._ Snakemake)
    * Add the project files (e.g. `Snakefile`, `config.yaml`, `environment.yaml`)
    * Install the Conda environment containing all packages run by the workflow
-->
