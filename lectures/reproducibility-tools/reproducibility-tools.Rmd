---
title: "Reproducible Research and Snakemake"
subtitle: "Snakemake BYOC NBIS course"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
    xaringan::moon_reader:
        self-contained: true
        seal: false
        css: ["default", "../template.css"]
        nature:
            slideNumberFormat: ""
---

layout: true
<div class="scilife-logo"></div>
<div class="nbis-logo"></div>

---

class: center, middle

.HUGE[Reproducible Research and Snakemake]

```{r Setup, echo = FALSE, message = FALSE}
# Knitr setup
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

# Load packages
library("dplyr")
library("kableExtra")
```

---

# Reproducibility

- Reproducible research is about being able to replicate the results of a study
- It is an important aspect of the scientific method
- Computational reproducibility is one part of it
- Ideally, given the same data and the same code, there are identical outcomes

--

*Code* encompasses
- The workflow itself (→ `Snakefile`)
- The helper scripts you are calling (→ `scripts/`)
- The 3rd-party tools you are running (→ this lecture)

---

# Computational reproducibility

Why the effort?

.tiny[M. Schwab et al. *Making scientific computations reproducible*. https://dx.doi.org/10.1109/5992.881708]

> Because many researchers typically forget details
> of their own work, they are not unlike strangers
> when returning to projects after time away.
> Thus, efforts to communicate your work to
> strangers can actually help you communicate
> with yourself over time.

--

→ **You** are also in the target audience


---

# Don’t be *that* person

The journal *Science* implemented a replication policy in 2011.
A study in 2018 requested raw data and code in accordance with the policy.
Some answers:

> When you approach a PI for the source codes and raw data, you better explain who you are,
> whom you work for, why you need the data and what you are going to do with it.

.
--

> I have to say that this is a very unusual request without any explanation!
> Please ask your supervisor to send me an email with a detailed, and I mean detailed, explanation.

(26% out of 204 randomly selected papers in the journal could be reproduced.)

.tiny[Stodden et. al (2018). *An empirical analysis of journal policy effectiveness for computational reproducibility* https://doi.org/10.1073/pnas.1708290115]

---

# Combine tools to make research reproducible

.center[<img src="reproducibility-overview.png" width=40%/>]

--

* Track code changes over time with .green[Git] and share it on .green[GitHub] (not here)

--

* Make your workflow reproducible with a workflow manager (.green[Snakemake], .green[Nextflow], .green[WDL])

--

* Make the execution environment reproducible with .green[Conda] environments and/or .green[containers]


---

# Conda: a .green[package], .green[dependency], and .green[environment] manager

* Conda installs packages
* Packages come from a central repository at https://anaconda.org/
* Users can contribute their own packages via *channels*
* Highly recommended: The [Bioconda](https://bioconda.github.io/) channel

---

# Using Conda

Prerequisites

* Install Conda, for example with [Miniconda](https://docs.conda.io/en/latest/miniconda.html)
* Set up the [Bioconda](https://bioconda.github.io/) channel

--

* Install Samtools and BWA into a new Conda environment named `mapping`:
```
$ conda create -n mapping samtools bwa
```

--

* Conda also installs also the .green[dependencies] – other software required by Samtools and/or BWA.

--

To use the tools in the environment, .green[activate] it:
```
$ conda activate mapping
$ samtools --version
samtools 1.15.1
```

--
* Install a tool into an existing environment:
```
conda install -n mapping bowtie2
```
(Leaving out `-n mapping` installs into the currently active environment.)

---

# Conda environments

* You can have as many environments as you wish
* Environments are independent from each other
* If something is broken, simply delete the environment and start over
* To test a new tool, install it into a Conda environment. Delete the environment to uninstall.

--

* Find tools to install by searching [anaconda.org](https://anaconda.org) or with `conda search`


---

# Conda environment files

* Conda environments can be created from .green[environment files].
* Example `bwa.yaml`:

```{yaml conda env one, eval = FALSE}
channels:
  - conda-forge
  - bioconda
  - defaults
dependencies:
  - bwa=0.7.17
```

--
* Create the environment:
```
conda env create -n bwa -f bwa.yaml
```

---

# Snakemake + Conda

## Option one: A single environment for the entire workflow

* Write an environment file (`environment.yaml`) that includes .green[all tools used by the workflow]:
```{python conda env big, eval=FALSE}
name: best-practice-smk
channels:
  - conda-forge
  - bioconda
  - default
dependencies:
  - snakemake=6.8.0   # ← Snakemake is part of the environment
...
  - multiqc=1.11   # ← Version numbers for reproducibility
  - samtools=1.13
```

--
* Create the environment, activate it and run the workflow within it:
```{bash snakemake conda env, eval=FALSE}
$ conda env create -f environment.yml
$ conda activate best-practice-smk
$ snakemake
```

--
* Possibly helpful: `conda export -n envname > environment.yaml`

.tiny[source: [best practice example](https://github.com/NBISweden/snakemake_best_practice)]

---
# Snakemake + Conda

## Option two: Rule-specific environments

You can let Snakemake create and activate Conda environments for you.

--
1. Create the environment file, such as `envs/bwa.yaml` (`envs/` is best practice)

--
1. Add the `conda:` directive to the rule:
```{python conda rule, eval = FALSE}
rule create_bwa_index:
    output: ...
    input: ...
    conda: "envs/bwa.yaml"  # ← Path to environment YAML file
    shell:
        "bwa index {input}"
```
--
1. Run `snakemake --use-conda`

--

* Snakemake creates the environment for you and re-uses it next time
* If the YAML file changes, the environment is re-created
* `conda:` does not work if you use `run:` (instead of `shell:` or `script:`)


.tiny[modified from: [best practice example](https://github.com/NBISweden/snakemake_best_practice)]


---

# Using a "module" system

* Conda environments can be large and slow to create

* Some cluster operators frown upon using it

--

* UPPMAX and other clusters have a .green[module] command for getting access to software:
```
$ module load bioinfo-tools bwa
```

--

* Snakemake supports this with the `envmodules:` directive:
```{bash, eval = FALSE}
rule create_bwa_index:
    output: ...
    input: ...
    envmodules:
      "bioinfo-tools",
      "bwa",
    conda: "envs/bwa.yaml"  # ← Fallback
    shell:
        "bwa index {input}"
```

--

* Run with `snakemake --use-envmodules`

--

* For reproducibility, [the Snakemake documentation recommends](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#using-environment-modules) to also include a `conda:` section

---

# Containers

* Containers represent another way of packaging applications

--

* Each container contains the application itself and .green[all dependencies and libraries] (that is, a functional Linux installation)

--

* It is fully .green[isolated] from the other software on the machine:
  By default, the tools in the container can only access what is in the container.

--

* The most common software for managing containers is .green[Docker]

---

# Containers

## Docker nomenclature

--
* A Docker .green[image] is a standalone executable package of software (on disk)

--
* A .green[Dockerfile] is a recipe used to build a Docker .green[image]

--
* A Docker .green[container] is a standard unit of software run on the Docker Engine
  (running an image gives a container)

--
* .green[DockerHub] is an online service for sharing Docker images

--

## Docker vs Singularity

* On high-performance clusters (HPC), Docker is often not installed due to security concerns.
  .green[Singularity] is often available as an alternative.

--
* Docker images can be converted into Singularity images

--
* → Singularity can be used to run Docker containers

---

# Running Snakemake jobs in containers

Snakemake can run a rule in a container, using Singularity

* Ensure your system has Singularity .green[installed]

--

* Find the Docker or Singularity .green[image] in which you want to run the rule (http://biocontainers.pro/ or [DockerHub](https://hub.docker.com/))

--

* Add the `container:` directive to your rule:

```{python singularity rule, eval = FALSE}
rule NAME:
    input:
        "table.txt"
    output:
        "plots/myplot.pdf"
    container:
        "docker://joseespinosa/docker-r-ggplot2"
    script:
        "scripts/plot-stuff.R"
```

.tiny[source: [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#running-jobs-in-containers)]

--

* Start your workflow on the command line with `--use-singularity`

```{bash snakemake use singularity, eval=FALSE}
$ snakemake --use-singularity
```


---

# Containers

## 2. Packaging your Snakemake workflow in a Docker container

--

* Make sure your system has Docker .green[installed]

--

* Write a .green[Docker file], _e.g._ [see this example](https://github.com/NBISweden/workshop-reproducible-research/blob/main/tutorials/docker/Dockerfile)

--

    * Start with the official `Ubuntu` image 
    * Install Miniconda and other required tools (_e.g._ Snakemake)
    * Add the project files (e.g. `Snakefile`, `config.yaml`, `environment.yaml`)
    * Install the Conda environment containing all packages run by the workflow

---

# Containers

## 2. Packaging your Snakemake workflow in a Docker container

* Create a Docker .green[image] from your Docker file (_e.g._ called `my_workflow`)

```{bash docker image, eval=FALSE}
$ docker build -t my_workflow .
```

--

* .green[Run] your container, _e.g._

```{bash docker run, eval=FALSE}
$ docker run my_workflow
```

--

* .green[Share] your Docker file on GitHub or BitBucket, or your Docker image on DockerHub

---

# Combinations of Conda and Containers

## Combine Conda-based package management with running jobs in containers

--

* A container can be specified globally (for the entire workflow) for a workflow 
  with rule-specific Conda environments

* Snakemake then runs each job in this container with its corresponding Conda 
  environment when run with `--use-conda --use-singularity`

.tiny[More info: [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#ad-hoc-combination-of-conda-package-management-with-containers) & [best practice example](https://github.com/NBISweden/snakemake_best_practice)]

---

# Combinations of Conda and Containers

## Containerization of Conda-based workflows

--

* Snakemake can automatically generate a Docker file that contains all
  Conda environments used by the rules of the workflow using the flag `--containerize` 

.tiny[More info: [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#containerization-of-conda-based-workflows)]

---

# Integrating foreign workflow management systems

* From version 6.2 on, Snakemake can run workflows written in other workflow 
  management systems such as .green[Nextflow] 

--

.pull-left[

* The workflow runs in .green[Snakemake] until a rule to run the foreign workflow is reached

* In this rule, Snakemake .green[hands over] to the other workflow manager

* Afterwards, .green[Snakemake] continues to run rules processing the output files of the foreign workflow

]

--

.pull-right[

```{python nextflow, eval = FALSE}
rule chipseq_pipeline:
    input:
        input="design.csv",
        fasta="data/genome.fasta",
        gtf="data/genome.gtf",
    output:
        "multiqc/broadPeaks/multiqc_report.html",
    params:
        pipeline="nf-core/chipseq",
        revision="1.2.1",
        profile=["conda"],
    handover: True
    wrapper:
        "0.74.0/utils/nextflow"
```

.tiny[More info & source: [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/foreign_wms.html)]

]

---

# Summary

There are many ways to use other .green[tools for reproducible research] together with Snakemake:

--

* Use .green[Git] to version control, backup and share your code

--

* Run rules or your entire workflow in .green[Conda] environments

--

* Run your rules in isolated Singularity .green[containers]

--

* Package your entire workflow in a .green[Docker container]

--

* Run pipelines written in .green[other workflow management systems] in your Snakemake workflow

---

class: center, middle

.HUGE[Questions?]

---


* Further reading: [conda-lock](https://github.com/conda-incubator/conda-lock)
