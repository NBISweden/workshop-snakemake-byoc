---
title: "Combining Tools for Reproducible Research with Snakemake"
subtitle: "Snakemake BYOC NBIS course"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
    xaringan::moon_reader:
        self-contained: true
        seal: false
        css: ["default", "../template.css"]
        nature:
            slideNumberFormat: ""
---

layout: true
<div class="scilife-logo"></div>
<div class="nbis-logo"></div>

---

class: center, middle

.HUGE[Combining Tools for Reproducible Research with Snakemake]

```{r Setup, echo = FALSE, message = FALSE}
# Knitr setup
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

# Load packages
library("dplyr")
library("kableExtra")
```

---

# Reproducibility is rarer than you think

The results of only 26% out of 204 randomly selected papers in the journal
*Science* could be reproduced.<sup>1</sup>

.tiny[<sup>1</sup> Stodden et. al (2018). "An empirical analysis of journal policy effectiveness for computational reproducibility". PNAS. 115 (11): 2584-2589]

--

> Many journals are revising author guidelines to include data and code
> availability.

--

> (...) an improvement over no policy, but currently insufficient for
> reproducibility.


---

# Combining Tools for Reproducible Research with Snakemake

.center[<img src="reproducibility-overview.png" width=40%/>]

--

* Track your Snakemake code with .green[Git] and share it in a remote .green[repository] on GitHub or BitBucket

--

* Combine Snakemake with .green[Conda] and/or .green[containers] to make the compute environment reproducible

--

* Integrate foreign workflow management systems such as .green[Nextflow] pipelines into your Snakemake workflow

---

# Git

* A widely used system for distributed version control to .green[version, backup and share] your code and documents

--

* Keeps a complete .green[history] of the changes you make to your files that can be re-visited & compared

--

* Git tracks .green[who contributed what] to your code

--

* Git is mainly used for .green[text files], not large or binary files, so ideal for Snakemake workflows

--

* You can publish your code along with your research paper by sharing it in a remote repository (e.g. on .green[GitHub] or .green[BitBucket])

---

# Conda

* Is a .green[package, dependency, and environment] manager

--

    > packages: any type of program (_e.g._ bowtie2, snakemake etc.)

    > dependency: other software required by a package

    > environment: a distinct collection of packages

--

* Keeps track of the dependencies between packages in each environment

---

# Conda

## 1. Running a Snakemake rule with a Conda environment

--

* Make sure you have Conda .green[installed] (Miniconda or Anaconda)

--

* Find your Conda .green[package] on http://anaconda.org

--

* Create a Conda .green[environment file] (e.g. `bwa.yaml`)

```{python conda env one, eval = FALSE}
channels:
  - conda-forge
  - bioconda
  - defaults
dependencies:
  - bwa=0.7.17
```

.tiny[source: [best practice example](https://github.com/NBISweden/snakemake_best_practice)]


--

* Store your `yaml` files in a directory for environments

--

* For reproducibility, it is important to keep include package .green[versions] in your environment file

---

# Conda

## 1. Running a Snakemake rule with a Conda environment

* Add the .green[path] to the Conda environment `yaml` file to your rule using the `conda` directive

--

```{python conda rule, eval = FALSE}
rule map_bwa_index:
    output: expand("{{ref}}{ext}", ext=[".amb", ".ann", ".bwt", ".pac", ".sa"])
    input: config["ref"]
    log: "logs/bwa/index/{ref}.log"
    conda: "../envs/bwa.yaml"
    shell:
        "bwa index {input}"
```

.tiny[modified from: [best practice example](https://github.com/NBISweden/snakemake_best_practice)]

--

* Start your workflow on the command line with `--use-conda`

```{bash snakemake use conda, eval=FALSE}
$ snakemake --use-conda
```

--

* This doesn't work if you use `run` instead of `shell` (or other directives)

---

# Conda

## 2. Using one Conda environment for the entire workflow

--

* Write a Conda .green[environment file] that includes all tools used by the workflow (save it as e.g. `environment.yaml`)

```{python conda env big, eval=FALSE}
name: best-practice-smk
channels:
  - conda-forge
  - bioconda
  - default
dependencies:
  - snakemake=6.8.0
  - python=3.8
  - pandas=1.3.3
  - jupyter=1.0
  - jupyter_contrib_nbextensions=0.5.1
  - jupyterlab_code_formatter=1.4
  - bwa=0.7.17
  - multiqc=1.11
  - r-ggplot2=3.3.5
  - samtools=1.13
```

.tiny[source: [best practice example](https://github.com/NBISweden/snakemake_best_practice)]

---

# Conda

## 2. Using one Conda environment for the entire workflow

* .green[Create] the environment

--

```{bash conda create, eval=FALSE}
$ conda env create -f environment.yml
```

--

* .green[Activate] your Conda environment

```{bash conda activate, eval=FALSE}
$ conda activate best-practice-smk
```

--

* Start your Snakemake workflow

```{bash snakemake conda env, eval=FALSE}
(best-practice-smk) [...] $ snakemake
```

---

# Containers

## What can I use containers for?

--

* Run applications securely .green[isolated] in a container, packaged with .green[all dependencies and libraries]

--

* As advanced .green[environment manager]

--

* To package your .green[code] with the environment it needs

--

* To package a whole .green[workflow] (*e.g.* to accompany a manuscript)

--

* And much more

--

## Docker vs. Singularity

--

* Docker was developed for .green[any operating system], but not for high-performance computing (HPC) clusters

--

* Singularity is an open source container platform suitable for .green[HPC clusters]

---

# Containers

## Docker nomenclature

--

* A Docker .green[file] is a recipe used to build a Docker .green[image]

--

* A Docker .green[image] is a standalone executable package of software

--

* A Docker .green[container] is a standard unit of software run on the Docker Engine

--

* .green[DockerHub] is an online service for sharing Docker images

--

* Docker images can be converted into Singularity images

---

# Containers

## 1. Running Snakemake rules with Singularity

--

* Snakemake can run a rule .green[isolated] in a container, using Singularity

--

* Conda packages are available as Docker and Singularity images (_e.g._ Conda packages from the [bioconda channel](http://biocontainers.pro))

--

* Many other Docker images are available on [DockerHub](https://hub.docker.com/)

--

* Or build your own Docker or Singularity images

---

# Containers

## 1. Running Snakemake rules with Singularity

--

* Make sure your system has Singularity .green[installed]

--

* Find your Docker or Singularity .green[image], _e.g._ on http://biocontainers.pro

--

* Add the .green[link] to the container image (or the path to a Singularity `*.sif` file) to your rule using the `container` directive

```{python singularity rule, eval = FALSE}
rule NAME:
    input:
        "table.txt"
    output:
        "plots/myplot.pdf"
    container:
        "docker://joseespinosa/docker-r-ggplot2"
    script:
        "scripts/plot-stuff.R"
```

.tiny[source: [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#running-jobs-in-containers)]

--

* Start your workflow on the command line with `--use-singularity`

```{bash snakemake use singularity, eval=FALSE}
$ snakemake --use-singularity
```

---

# Containers

## 2. Packaging your Snakemake workflow in a Docker container

--

* Make sure your system has Docker .green[installed]

--

* Write a .green[Docker file], _e.g._

--

    * Start with the official `Ubuntu` image 
    * Install Miniconda and other required tools (_e.g._ Snakemake)
    * Add the project files (e.g. `Snakefile`, `config.yaml`, `environment.yaml`)
    * Install the Conda environment containing all packages run by the workflow


.tiny[see this [example](https://github.com/NBISweden/workshop-reproducible-research/blob/main/tutorials/docker/Dockerfile)]

---

# Containers

## 2. Packaging your Snakemake workflow in a Docker container

* Create a Docker .green[image] from your Docker file (_e.g._ called `my_workflow`)

```{bash docker image, eval=FALSE}
$ docker build -t my_workflow .
```

--

* .green[Run] your container, _e.g._

```{bash docker run, eval=FALSE}
$ docker run my_workflow
```

--

* .green[Share] your Docker file on GitHub or BitBucket, or your Docker image on DockerHub

---

# Combinations of Conda and Containers

--

.pull-left[

## Combine Conda-based package management with running jobs in containers

* A global container can be specified for the entire workflow in which Snakemake runs jobs 
  with rule-specific Conda environments when run with `--use-conda --use-singularity`

.tiny[More info: [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#ad-hoc-combination-of-conda-package-management-with-containers) & [best practice example](https://github.com/NBISweden/snakemake_best_practice)]

]

--

.pull-right[

## Containerization of Conda-based workflows

* Snakemake can automatically generate a Docker file that contains all
  Conda environments used by the rules of the workflow using the flag `--containerize` 

.tiny[More info: [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#containerization-of-conda-based-workflows)]

]

---

# Integrating foreign workflow management systems

* From version 6.2 on, Snakemake can run workflows written in other workflow 
  management systems such as .green[Nextflow] 

--

.pull-left[

* The workflow is run in .green[Snakemake] until a rule to run the foreign workflow is reached

* In this rule, Snakemake .green[hands over] to the other workflow management system

* Afterwards, .green[Snakemake] continues running rules that use the output files of the foreign workflow

]

--

.pull-right[

```{python nextflow, eval = FALSE}
rule chipseq_pipeline:
    input:
        input="design.csv",
        fasta="data/genome.fasta",
        gtf="data/genome.gtf",
    output:
        "multiqc/broadPeaks/multiqc_report.html",
    params:
        pipeline="nf-core/chipseq",
        revision="1.2.1",
        profile=["conda"],
    handover: True
    wrapper:
        "0.74.0/utils/nextflow"
```

.tiny[More info & source: [Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/foreign_wms.html)]

]

---

# Summary

There are many ways to use other .green[tools for reproducible research] together with Snakemake:

--

* Use .green[Git] to version control, backup and share your code

--

* Run rules or your entire workflow in .green[Conda] environments

--

* Run your rules in isolated Singularity .green[containers]

--

* Package your entire workflow in a .green[Docker container]

--

* Run pipelines written in .green[other workflow management systems] in your Snakemake workflow

---

class: center, middle

.HUGE[Questions?]

---