---
title: "Reproducible Research and Snakemake"
subtitle: "Snakemake BYOC NBIS course"
date: 2024-05-28
format:
  revealjs:
    theme:
      - white
      - ../custom.scss
    self-contained: false
    toc: false
    toc-depth: 1
    slide-level: 2
    slide-number: true
    #preview-links: true
    #chalkboard: true
    # Multiple logos not possible; would need to make custom logo combining both logos
    footer: Snakemake BYOC 2024 - Reproducible Research
    logo: https://nbis.se/nbislogo-green.svg
    smaller: true
    highlight-style: gruvbox
    fig-height: 3
    fig-width: 3
    code-line-numbers: false
execute:
  echo: true
  #warning: false
  #cache: false
  #include: true
  #autodep: true
  eval: false
  #error: true

---

## Reproducibility

- Reproducible research is about being able to replicate the results of a study
- It is an important aspect of the scientific method
-  **Computational reproducibility** is one part of it
- Ideally, given the **same data** and the **same code**, there are identical outcomes

. . .

### Code encompasses

- The workflow itself (→ `Snakefile`)
- The helper scripts you are calling (→ `scripts/`)
- The 3rd-party tools you are running/the execution environment (→ this lecture)


## Computational reproducibility

Why the effort?

> Because many researchers typically forget details
> of their own work, they are not unlike strangers
> when returning to projects after time away.
> Thus, efforts to communicate your work to
> strangers can actually help you communicate
> with yourself over time.

M. Schwab et al.
*Making scientific computations reproducible*.\
<https://dx.doi.org/10.1109/5992.881708>

. . .

→ **You** are part of the target audience


## Don’t be *that* person

* *Science* implemented a replication policy in 2011.
* A study in 2018 (Stodden et. al, <https://doi.org/10.1073/pnas.1708290115>)
requested raw data and code in accordance with the policy.
* Some answers:

. . .

> When you approach a PI for the source codes and raw data, you better explain who you are,
> whom you work for, why you need the data and what you are going to do with it.

. . .

> I have to say that this is a very unusual request without any explanation!
> Please ask your supervisor to send me an email with a detailed, and I mean detailed, explanation.

. . .

26% out of 204 randomly selected papers in the journal could be reproduced.


## Combining tools to make research reproducible

![](reproducibility-overview.png){fig-align="center"}

::: {.incremental}

* Track code changes over time with **Git** and share it on [GitHub](https://github.com) (not this talk)
* Make your workflow reproducible with a workflow manager (**Snakemake**, **Nextflow**, **WDL**)
* Make the execution environment reproducible with **Conda** environments and/or **containers**

:::

## Conda: a **package**, **dependency**, and **environment** manager

* Conda installs packages
* Packages come from a central repository at <https://anaconda.org/>
* Users can contribute their own packages via *channels*
* Highly recommended: The [Bioconda](https://bioconda.github.io/) channel


## Using Conda

::: {.incremental}

* Install Conda (through [Miniconda](https://docs.anaconda.com/free/miniconda/))
* Set up the [Bioconda](https://bioconda.github.io/) channel
* Install Samtools and BWA into a new **Conda environment** named `mapping`:

  ```bash
  $ conda create -n mapping samtools bwa
  ```

* Conda also installs all **dependencies** – other software required by Samtools and/or BWA.
To use the tools in the environment, **activate** it:

  ```bash
  $ conda activate mapping
  $ samtools --version
  samtools 1.15.1
  ```

* Install a tool into an existing environment:

  ```bash
  conda install -n mapping bowtie2
  ```
  (Leaving out `-n mapping` installs into the currently active environment.)

:::


## Conda environments

::: {.incremental}

* You can have as many environments as you wish
* Environments are independent
* If something is broken, simply delete the environment and start over

  ```bash
  $ conda env remove -n mapping
  ```

* To test a new tool, install it into a fresh Conda environment. Delete the environment to uninstall.

* Find packages by searching [anaconda.org](https://anaconda.org) or with `conda search`

:::


## Conda environment files

::: {.incremental}

* Conda environments can be created from **environment files** in YAML format.
* Example `bwa.yaml`:

  ```yaml
  channels:
    - conda-forge
    - bioconda
    - defaults
  dependencies:
    - bwa=0.7.17
  ```

* Create the environment:

  ```bash
  $ conda env create -n bwa -f bwa.yaml
  ```

:::


## Snakemake + Conda

### Option one: A single environment for the entire workflow

* Write an environment file (`environment.yaml`) that includes **all tools used by the workflow**:

  ```yaml
  name: best-practice-smk
  channels:
    - conda-forge
    - bioconda
    - default
  dependencies:
    - snakemake=6.8.0   # ← Snakemake is part of the environment
  ...
    - multiqc=1.11   # ← Version numbers for reproducibility
    - samtools=1.13
  ```

. . .

* Create the environment, activate it and run the workflow within it:

  ```bash
  $ conda env create -f environment.yml
  $ conda activate best-practice-smk
  $ snakemake
  ```

. . .

* Possibly helpful: `conda export -n envname > environment.yaml`

source: [best practice example](https://github.com/NBISweden/snakemake_best_practice)


## Snakemake + Conda

### Option two: Rule-specific environments

You can let Snakemake create and activate Conda environments for you.

::: {.incremental}

* Create the environment file, such as `envs/bwa.yaml` (`envs/` is best practice)
* Add the `conda:` directive to the rule:

  ```{python conda rule, eval = FALSE}
  rule create_bwa_index:
      output: ...
      input: ...
      conda: "envs/bwa.yaml"  # ← Path to environment YAML file
      shell:
          "bwa index {input}"
  ```
* Run `snakemake --use-conda`
* Snakemake creates the environment for you and re-uses it next time
* If the YAML file changes, the environment is re-created
* `conda:` does not work if you use `run:` (instead of `shell:` or `script:`)

:::

modified from: [best practice example](https://github.com/NBISweden/snakemake_best_practice)


## Using a "module" system

* Conda environments can be large and slow to create
* Some cluster operators frown upon using it

. . .

* UPPMAX, dardel and other clusters have a **module** command for getting access to software:

  ```
  $ module load bioinfo-tools bwa
  ```

. . .

* Snakemake supports this with the `envmodules:` directive:

  ```bash
  rule create_bwa_index:
      output: ...
      input: ...
      envmodules:
        "bioinfo-tools",
        "bwa",
      conda: "envs/bwa.yaml"  # ← Fallback
      shell:
          "bwa index {input}"
  ```

* Run with `snakemake --use-envmodules`

* For reproducibility, [the Snakemake documentation recommends](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#using-environment-modules) to also include a `conda:` section


## Containers

::: {.incremental}

* Containers represent another way of packaging applications
* Each container contains the application itself and **all system-level dependencies and libraries** (that is, a functional Linux installation)
* It is fully **isolated** from the other software on the machine:
  By default, the tools in the container can only access what is in the container.
* The most common software for managing containers is **Docker**

:::


## Containers

### Docker nomenclature

::: {.incremental}

* A Docker **image** is a standalone executable package of software (on disk)
* A **Dockerfile** is a recipe used to build a Docker **image**
* A Docker **container** is a standard unit of software run on the Docker Engine
  (running an image gives a container)
* **DockerHub** is an online service for sharing Docker images

:::

### Docker vs Singularity

::: {.incremental}

* On high-performance clusters (HPC), Docker is often not installed due to security concerns.
  **Singularity** is often available as an alternative.
* Docker images can be converted into Singularity images
* → Singularity can be used to run Docker containers

:::


## Running Snakemake jobs in containers

Snakemake can run a jobs in a container using Singularity

* Ensure your system has Singularity installed

. . .

* Find a Docker or Singularity image with the tool to run (<https://biocontainers.pro/> or [DockerHub](https://hub.docker.com/))

. . .

* Add the `container:` directive to your rule:

  ```python
  rule minimap2_version:
      container: "docker://quay.io/biocontainers/minimap2:2.24--h5bf99c6_0"   # ← "docker://" is needed
      shell:
          "minimap2 --version"
  ```

. . .

* Start your workflow on the command line with `--use-singularity`

  ```bash
  $ snakemake --use-singularity -j 1
  ...
  Pulling singularity image docker://quay.io/biocontainers/minimap2:2.24--h5bf99c6_0.
  ...
  Activating singularity image .../.snakemake/singularity/342e6ddbac7e5929a11e6ae9350454c0.simg
  INFO:    Converting SIF file to temporary sandbox...
  2.24-r1122
  INFO:    Cleaning up image...
  ...
  ```


## Containers – advanced topics

::: {.incremental}

* A [Docker image to use for *all* rules can be specified](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#running-jobs-in-containers)

* You can package your entire workflow into a Docker image by writing a **Dockerfile**.
  [See this example](https://github.com/NBISweden/workshop-reproducible-research/blob/0ee1eca78ccefbd06fbeb2c0aba37030230df90d/tutorials/containers/Dockerfile)
  - Snakemake runs *inside* the container.
  - To run the workflow, only Docker or Singularity is needed

* [Conda and containers can be combined]([Snakemake documentation](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#ad-hoc-combination-of-conda-package-management-with-containers)): Specify a global container, run with `--use-conda --use-singularity`, and Snakemake creates the Conda environment within the container.

* [Snakemake can automatically generate a Dockerfile](https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#containerization-of-conda-based-workflows)
  that contains all Conda environments used by the rules of the workflow using the flag
  `--containerize`.

:::

## Summary

There are many ways to use other **tools for reproducible research** together with Snakemake:

::: {.incremental}

* Use **Git** for version control, backup and share your code
* Run rules or your entire workflow in **Conda** environments
* Run your rules in isolated Docker/Singularity **containers**
* Package your entire workflow in a **Docker container**

:::

<!--

* Further reading: [conda-lock](https://github.com/conda-incubator/conda-lock)


  * This starts from an Ubuntu image, installs Miniconda, Snakemake, adds relevant files such as `the workflow files
    * Install Miniconda and other required tools (_e.g._ Snakemake)
    * Add the project files (e.g. `Snakefile`, `config.yaml`, `environment.yaml`)
    * Install the Conda environment containing all packages run by the workflow
-->
