---
title: "Scatter/gather-operations in Snakemake"
subtitle: "Snakemake BYOC NBIS course"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
    xaringan::moon_reader:
        self-contained: true
        seal: false
        css: ["default", "../template.css"]
        nature:
            slideNumberFormat: ""
---

layout: true
<div class="scilife-logo"></div>
<div class="nbis-logo"></div>

---

class: center, middle

.HUGE[Scatter/gather-operations]
<br>
.HUGE[in Snakemake]

```{r Setup, echo = FALSE, message = FALSE}
# Knitr setup
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

# Load packages
library("dplyr")
library("kableExtra")
```

---

# What does scatter/gather mean?

--

* .green[Scatter]: one sample yields many downstream samples or results

--

* .green[Gather]: many samples yield one downstream sample or result

--

* A common use-case: multiplexed data

---

# A multiplexed pipeline

* .green[Plate]
    * Multiple plates per sequencing run
    * Each plate comes in its own FastQ file

--

* .green[Sample]
    * Multiple samples per plate
    * Identified by sample-level barcodes in each sequenced read
    * Sample barcodes are identical across plates

---

# The analyses

1. Demultiplex each plate into separate samples (.green[scatter])

--

2. Perform quality controls on each sample

--

3. Collect QC metrics into single, per-plate files (.green[gather])

---

# Metadata

An example `metadata.txt` file might contain data like so:

```{r Metadata structure, echo = FALSE}
# Function for creating tables
create_table <- function(data, full_width = TRUE) {
    data %>%
        kable() %>%
        kable_styling(bootstrap_options = c("striped", "hover"),
                      font_size         = 12,
                      fixed_thead       = TRUE,
                      full_width        = full_width,
                      position          = "left")
}

# Define and show metadata
metadata <- data.frame(plate_id    = c(rep("plate_1", 2), rep("plate_2", 2)),
                       sample_id   = paste0("sample_", seq_len(4)),
                       barcode_id  = seq_len(4),
                       barcode_seq = c("TTTTTTTTTA", "TTTTTTTTAA",
                                       "TTTTTTTAAA", "TTTTTTAAAA"))
create_table(metadata)
```

--

This metadata can be used as input to the pipeline:

```{python Read metadata, eval = FALSE}
# Import relevant modules
import pandas as pd

# Read metadata
metadata = pd.read_csv('metadata.txt', sep = '\t')

# Define plate and barcode IDs
plates = metadata['plate_id'].unique().tolist()
barcodes = metadata['barcode_id'].unique().tolist()
```

---

# Step 1: Demultiplexing

```{python demultiplexing 1, eval = FALSE}
rule A_demultiplex:
    input:
        data = '{plate}.fastq.gz',
    output:
        expand('{{plate}}-{sample}.fastq.gz', sample = barcodes)
```

Notice the double curly brackets (`{{plate}}`) in the `expand()` call:
this expands the barcode IDs (identical across plates) but keeps `plate` as a
Snakemake wildcard.

---

# Step 2: Quality controls

```{python demultiplexing 2, eval = FALSE}
rule A_demultiplex:
    input:
        data = '{plate}.fastq.gz',
    output:
        expand('{{plate}}-{sample}.fastq.gz', sample = barcodes)
```

Notice the double curly brackets (`{{plate}}`) in the `expand()` call:
this expands the barcode IDs (identical across plates) but keeps `plate` as a
Snakemake wildcard.

```{python quality controls 1, eval = FALSE}
rule B_quality_controls:
    input:
        rules.A_demultiplex.output
    output:
        '{plate}-{sample}_fastqc.zip'
```

This rule allows for any combination of `plate` and `sample`, thus running once
per sample per plate.

---

# Step 3: Collecting per-plate results

```{python demultiplexing 3, eval = FALSE}
rule A_demultiplex:
    input:
        data = '{plate}.fastq.gz',
    output:
        expand('{{plate}}-{sample}.fastq.gz', sample = barcodes)
```

Notice the double curly brackets (`{{plate}}`) in the `expand()` call:
this expands the barcode IDs (identical across plates) but keeps `plate` as a
Snakemake wildcard.

```{python quality controls 2, eval = FALSE}
rule B_quality_controls:
    input:
        rules.A_demultiplex.output
    output:
        '{plate}-{sample}_fastqc.zip'
```

This rule allows for any combination of `plate` and `sample`, thus running once
per sample per plate.

```{python Collect results, eval = FALSE}
rule C_collect_results:
    input:
        expand('{{plate}}-{sample}_fastqc.zip', sample = barcodes)
    output:
        '{plate}.collected_QC.txt'
```

We use the same nested curly brackets as for the first rule, but for the input
instead.

---

# Putting it all together

```{python Putting it all together, eval = FALSE}
# Import relevant modules
import pandas as pd

# Read metadata
metadata = pd.read_csv('metadata.txt', sep = '\t')

# Define plate and barcode IDs
plates = metadata['plate_id'].unique().tolist()
barcodes = metadata['barcode_id'].unique().tolist()

# Define rules
rule A_demultiplex:
    input:
        data = '{plate}.fastq.gz',
    output:
        expand('{{plate}}-{sample}.fastq.gz', sample = barcodes)

rule B_quality_controls:
    input:
        rules.A_demultiplex.output
    output:
        '{plate}-{sample}_fastqc.zip'

rule C_collect_results:
    input:
        expand('{{plate}}-{sample}_fastqc.zip', sample = barcodes)
    output:
        '{plate}.collected_QC.txt'
```

--

Finally, an `all` rule with input FASTQ files:

```{python Rule all, eval = FALSE}
rule all:
    input:
        expand('input_plate_{plate}.collected_QC.txt', plate = plates)
```

---

# Adding more complexity

--

* Adding additional and/or .green[nested layers], *e.g.* sequencing run or
  sample/treatment groups

--

* Collecting the collected .green[results into a single file] for further
  analyses and/or statistics
